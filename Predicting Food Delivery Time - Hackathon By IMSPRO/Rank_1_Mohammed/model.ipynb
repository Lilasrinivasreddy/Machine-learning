{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Adding-Cuisines-as-Features\" data-toc-modified-id=\"Adding-Cuisines-as-Features-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Adding Cuisines as Features</a></span></li><li><span><a href=\"#Adding-City-as-Feature\" data-toc-modified-id=\"Adding-City-as-Feature-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Adding City as Feature</a></span></li><li><span><a href=\"#Numerical-Feature-Cleaning\" data-toc-modified-id=\"Numerical-Feature-Cleaning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Numerical Feature Cleaning</a></span></li><li><span><a href=\"#Other-useful-Derived-Features\" data-toc-modified-id=\"Other-useful-Derived-Features-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Other useful Derived Features</a></span></li><li><span><a href=\"#Model-Training-on-Complete-Data\" data-toc-modified-id=\"Model-Training-on-Complete-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Training on Complete Data</a></span></li><li><span><a href=\"#Ensembling-lightgbm-and-RF-model\" data-toc-modified-id=\"Ensembling-lightgbm-and-RF-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Ensembling lightgbm and RF model</a></span></li><li><span><a href=\"#Second-Layer---Mode-based-Ensemble\" data-toc-modified-id=\"Second-Layer---Mode-based-Ensemble-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Second Layer - Mode based Ensemble</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11094, 9)\n",
      "(2774, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "pd.set_option(\"max_columns\", 1000)\n",
    "\n",
    "# Load data\n",
    "train = pd.read_excel('../input/Data_Train.xlsx', index_col=None)\n",
    "test = pd.read_excel('../input/Data_Test.xlsx', index_col=None)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Delivery_Time\"\n",
    "train_target = train[target]\n",
    "train.drop([target], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class mapping {10: 0, 20: 1, 30: 2, 45: 3, 65: 4, 80: 5, 120: 6}\n",
      "class mapping reverse {0: 10, 1: 20, 2: 30, 3: 45, 4: 65, 5: 80, 6: 120}\n"
     ]
    }
   ],
   "source": [
    "# Converting the classes to integer values. \n",
    "# Since this is a multi class classfication problem. The class mapping will be useful when ensembling various models.\n",
    "train_target = train_target.apply(lambda x: x.split()[0]).astype(int)\n",
    "\n",
    "class_map = {}\n",
    "class_map_rev = {}\n",
    "for a,b in enumerate(sorted(train_target.unique())):\n",
    "    class_map[b] = a\n",
    "    class_map_rev[a] = b\n",
    "print(\"class mapping {}\".format(class_map))\n",
    "print(\"class mapping reverse {}\".format(class_map_rev))\n",
    "\n",
    "train_target = train_target.map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique cuisines 101\n",
      "unique cuisines are {'North Indian', 'French', 'Mithai', 'Konkan', 'Bohri', 'Cafe', 'Bakery', 'Turkish', 'North Eastern', 'Mishti', 'Bubble Tea', 'Hot dogs', 'Vietnamese', 'Pizza', 'Japanese', 'Odia', 'Mughlai', 'Tamil', 'Maharashtrian', 'Rolls', 'Momos', 'Bengali', 'Naga', 'Mangalorean', 'Indian', 'Thai', 'Mexican', 'Korean', 'Tibetan', 'Chettinad', 'Biryani', 'Parsi', 'Raw Meats', 'Street Food', 'Middle Eastern', 'Assamese', 'Burger', 'Rajasthani', 'Roast Chicken', 'Tex-Mex', 'South Indian', 'Bangladeshi', 'Ice Cream', 'Goan', 'Malaysian', 'Pok√©', 'Asian', 'Finger Food', 'Iranian', 'Cantonese', 'Coffee', 'South American', 'Seafood', 'Lucknowi', 'Charcoal Chicken', 'American', 'Bar Food', 'Paan', 'Malwani', 'Kebab', 'Lebanese', 'Belgian', 'Continental', 'Andhra', 'Frozen Yogurt', 'Wraps', 'Italian', 'Kashmiri', 'Bihari', 'African', 'Kerala', 'Sri Lankan', 'Greek', 'Chinese', 'Gujarati', 'Desserts', 'Awadhi', 'Juices', 'Indonesian', 'Healthy Food', 'Brazilian', 'European', 'Hyderabadi', 'Spanish', 'Portuguese', 'Afghan', 'BBQ', 'Arabian', 'Fast Food', 'Burmese', 'German', 'Steak', 'Sandwich', 'Modern Indian', 'Tea', 'Mediterranean', 'Beverages', 'Nepalese', 'Israeli', 'Sushi', 'Salad'}\n"
     ]
    }
   ],
   "source": [
    "alldata = pd.concat([train, test], axis=0, sort=False, ignore_index=True)\n",
    "\n",
    "\n",
    "def determine_unique_cuisines():\n",
    "    cuisines_list = [val for val in alldata['Cuisines'].str.split(\",\")]\n",
    "    cuisines_list = [\",\".join([v.strip() for v in val]) for val in cuisines_list]\n",
    "    unique_cuisines = set(\",\".join(cuisines_list).split(\",\"))\n",
    "    print(\"total unique cuisines {}\".format(len(unique_cuisines)))\n",
    "    print(\"unique cuisines are {}\".format(unique_cuisines))\n",
    "\n",
    "    return unique_cuisines\n",
    "\n",
    "unique_cuisines =  determine_unique_cuisines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Cuisines as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527c4c1886404a0886c9aeca0e7cd180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Location</th>\n",
       "      <th>Average_Cost</th>\n",
       "      <th>Minimum_Order</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>North Indian</th>\n",
       "      <th>French</th>\n",
       "      <th>Mithai</th>\n",
       "      <th>Konkan</th>\n",
       "      <th>Bohri</th>\n",
       "      <th>Cafe</th>\n",
       "      <th>Bakery</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>North Eastern</th>\n",
       "      <th>Mishti</th>\n",
       "      <th>Bubble Tea</th>\n",
       "      <th>Hot dogs</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Pizza</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Odia</th>\n",
       "      <th>Mughlai</th>\n",
       "      <th>Tamil</th>\n",
       "      <th>Maharashtrian</th>\n",
       "      <th>Rolls</th>\n",
       "      <th>Momos</th>\n",
       "      <th>Bengali</th>\n",
       "      <th>Naga</th>\n",
       "      <th>Mangalorean</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Tibetan</th>\n",
       "      <th>Chettinad</th>\n",
       "      <th>Biryani</th>\n",
       "      <th>Parsi</th>\n",
       "      <th>Raw Meats</th>\n",
       "      <th>Street Food</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>Assamese</th>\n",
       "      <th>Burger</th>\n",
       "      <th>Rajasthani</th>\n",
       "      <th>Roast Chicken</th>\n",
       "      <th>Tex-Mex</th>\n",
       "      <th>South Indian</th>\n",
       "      <th>Bangladeshi</th>\n",
       "      <th>Ice Cream</th>\n",
       "      <th>Goan</th>\n",
       "      <th>Malaysian</th>\n",
       "      <th>Pok√©</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Finger Food</th>\n",
       "      <th>Iranian</th>\n",
       "      <th>Cantonese</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>South American</th>\n",
       "      <th>Seafood</th>\n",
       "      <th>Lucknowi</th>\n",
       "      <th>Charcoal Chicken</th>\n",
       "      <th>American</th>\n",
       "      <th>Bar Food</th>\n",
       "      <th>Paan</th>\n",
       "      <th>Malwani</th>\n",
       "      <th>Kebab</th>\n",
       "      <th>Lebanese</th>\n",
       "      <th>Belgian</th>\n",
       "      <th>Continental</th>\n",
       "      <th>Andhra</th>\n",
       "      <th>Frozen Yogurt</th>\n",
       "      <th>Wraps</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Kashmiri</th>\n",
       "      <th>Bihari</th>\n",
       "      <th>African</th>\n",
       "      <th>Kerala</th>\n",
       "      <th>Sri Lankan</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Gujarati</th>\n",
       "      <th>Desserts</th>\n",
       "      <th>Awadhi</th>\n",
       "      <th>Juices</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Healthy Food</th>\n",
       "      <th>Brazilian</th>\n",
       "      <th>European</th>\n",
       "      <th>Hyderabadi</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Afghan</th>\n",
       "      <th>BBQ</th>\n",
       "      <th>Arabian</th>\n",
       "      <th>Fast Food</th>\n",
       "      <th>Burmese</th>\n",
       "      <th>German</th>\n",
       "      <th>Steak</th>\n",
       "      <th>Sandwich</th>\n",
       "      <th>Modern Indian</th>\n",
       "      <th>Tea</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Beverages</th>\n",
       "      <th>Nepalese</th>\n",
       "      <th>Israeli</th>\n",
       "      <th>Sushi</th>\n",
       "      <th>Salad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_6321</td>\n",
       "      <td>FTI College, Law College Road, Pune</td>\n",
       "      <td>‚Çπ200</td>\n",
       "      <td>‚Çπ50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_2882</td>\n",
       "      <td>Sector 3, Marathalli</td>\n",
       "      <td>‚Çπ100</td>\n",
       "      <td>‚Çπ50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1595</td>\n",
       "      <td>Mumbai Central</td>\n",
       "      <td>‚Çπ150</td>\n",
       "      <td>‚Çπ50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_5929</td>\n",
       "      <td>Sector 1, Noida</td>\n",
       "      <td>‚Çπ250</td>\n",
       "      <td>‚Çπ99</td>\n",
       "      <td>3.7</td>\n",
       "      <td>176</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_6123</td>\n",
       "      <td>Rmz Centennial, I Gate, Whitefield</td>\n",
       "      <td>‚Çπ200</td>\n",
       "      <td>‚Çπ99</td>\n",
       "      <td>3.2</td>\n",
       "      <td>521</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant                             Location Average_Cost Minimum_Order  \\\n",
       "0    ID_6321  FTI College, Law College Road, Pune         ‚Çπ200           ‚Çπ50   \n",
       "1    ID_2882                 Sector 3, Marathalli         ‚Çπ100           ‚Çπ50   \n",
       "2    ID_1595                       Mumbai Central         ‚Çπ150           ‚Çπ50   \n",
       "3    ID_5929                      Sector 1, Noida         ‚Çπ250           ‚Çπ99   \n",
       "4    ID_6123   Rmz Centennial, I Gate, Whitefield         ‚Çπ200           ‚Çπ99   \n",
       "\n",
       "  Rating Votes Reviews  North Indian  French  Mithai  Konkan  Bohri  Cafe  \\\n",
       "0    3.5    12       4             0       0       0       0      0     0   \n",
       "1    3.5    11       4             0       0       0       0      0     0   \n",
       "2    3.6    99      30             0       0       0       0      0     0   \n",
       "3    3.7   176      95             1       0       0       0      0     0   \n",
       "4    3.2   521     235             0       0       0       0      0     1   \n",
       "\n",
       "   Bakery  Turkish  North Eastern  Mishti  Bubble Tea  Hot dogs  Vietnamese  \\\n",
       "0       0        0              0       0           0         0           0   \n",
       "1       0        0              0       0           0         0           0   \n",
       "2       0        0              0       0           0         0           0   \n",
       "3       0        0              0       0           0         0           0   \n",
       "4       0        0              0       0           0         0           0   \n",
       "\n",
       "   Pizza  Japanese  Odia  Mughlai  Tamil  Maharashtrian  Rolls  Momos  \\\n",
       "0      0         0     0        0      0              0      1      0   \n",
       "1      0         0     0        0      0              0      0      0   \n",
       "2      0         0     0        0      0              0      0      0   \n",
       "3      0         0     0        1      0              0      0      0   \n",
       "4      0         0     0        0      0              0      0      0   \n",
       "\n",
       "   Bengali  Naga  Mangalorean  Indian  Thai  Mexican  Korean  Tibetan  \\\n",
       "0        0     0            0       0     0        0       0        0   \n",
       "1        0     0            0       0     0        0       0        0   \n",
       "2        0     0            0       0     0        0       0        0   \n",
       "3        0     0            0       0     0        0       0        0   \n",
       "4        0     0            0       0     0        0       0        0   \n",
       "\n",
       "   Chettinad  Biryani  Parsi  Raw Meats  Street Food  Middle Eastern  \\\n",
       "0          0        0      0          0            0               0   \n",
       "1          0        0      0          0            0               0   \n",
       "2          0        0      0          0            1               0   \n",
       "3          0        0      0          0            0               0   \n",
       "4          0        0      0          0            0               0   \n",
       "\n",
       "   Assamese  Burger  Rajasthani  Roast Chicken  Tex-Mex  South Indian  \\\n",
       "0         0       1           0              0        0             0   \n",
       "1         0       0           0              0        0             0   \n",
       "2         0       0           0              0        0             0   \n",
       "3         0       0           0              0        0             0   \n",
       "4         0       0           0              0        0             0   \n",
       "\n",
       "   Bangladeshi  Ice Cream  Goan  Malaysian  Pok√©  Asian  Finger Food  Iranian  \\\n",
       "0            0          0     0          0     0      0            0        0   \n",
       "1            0          1     0          0     0      0            0        0   \n",
       "2            0          0     0          0     0      0            0        0   \n",
       "3            0          0     0          0     0      0            0        0   \n",
       "4            0          0     0          0     0      0            0        0   \n",
       "\n",
       "   Cantonese  Coffee  South American  Seafood  Lucknowi  Charcoal Chicken  \\\n",
       "0          0       0               0        0         0                 0   \n",
       "1          0       0               0        0         0                 0   \n",
       "2          0       0               0        0         0                 0   \n",
       "3          0       0               0        0         0                 0   \n",
       "4          0       0               0        0         0                 0   \n",
       "\n",
       "   American  Bar Food  Paan  Malwani  Kebab  Lebanese  Belgian  Continental  \\\n",
       "0         0         0     0        0      0         0        0            0   \n",
       "1         0         0     0        0      0         0        0            0   \n",
       "2         0         0     0        0      0         0        0            0   \n",
       "3         0         0     0        0      0         0        0            0   \n",
       "4         0         0     0        0      0         0        0            0   \n",
       "\n",
       "   Andhra  Frozen Yogurt  Wraps  Italian  Kashmiri  Bihari  African  Kerala  \\\n",
       "0       0              0      1        0         0       0        0       0   \n",
       "1       0              0      0        0         0       0        0       0   \n",
       "2       0              0      0        1         0       0        0       0   \n",
       "3       0              0      0        0         0       0        0       0   \n",
       "4       0              0      0        0         0       0        0       0   \n",
       "\n",
       "   Sri Lankan  Greek  Chinese  Gujarati  Desserts  Awadhi  Juices  Indonesian  \\\n",
       "0           0      0        0         0         0       0       0           0   \n",
       "1           0      0        0         0         1       0       0           0   \n",
       "2           0      0        0         0         0       0       0           0   \n",
       "3           0      0        1         0         0       0       0           0   \n",
       "4           0      0        0         0         0       0       0           0   \n",
       "\n",
       "   Healthy Food  Brazilian  European  Hyderabadi  Spanish  Portuguese  Afghan  \\\n",
       "0             0          0         0           0        0           0       0   \n",
       "1             0          0         0           0        0           0       0   \n",
       "2             0          0         0           0        0           0       0   \n",
       "3             0          0         0           0        0           0       0   \n",
       "4             0          0         0           0        0           0       0   \n",
       "\n",
       "   BBQ  Arabian  Fast Food  Burmese  German  Steak  Sandwich  Modern Indian  \\\n",
       "0    0        0          1        0       0      0         0              0   \n",
       "1    0        0          0        0       0      0         0              0   \n",
       "2    0        0          1        0       0      0         0              0   \n",
       "3    0        0          0        0       0      0         0              0   \n",
       "4    0        0          0        0       0      0         0              0   \n",
       "\n",
       "   Tea  Mediterranean  Beverages  Nepalese  Israeli  Sushi  Salad  \n",
       "0    0              0          0         0        0      0      1  \n",
       "1    0              0          0         0        0      0      0  \n",
       "2    0              0          0         0        0      0      0  \n",
       "3    0              0          0         0        0      0      0  \n",
       "4    0              0          1         0        0      0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_vals_list = []\n",
    "for i, row in tqdm(alldata.iterrows()):\n",
    "    location_dict = {k:0 for k in unique_cuisines}\n",
    "    for k in row['Cuisines'].split(\",\"):\n",
    "        location_dict[k.strip()] = 1\n",
    "    cuisine_vals_list.append(location_dict)\n",
    "    \n",
    "alldata = alldata.drop(\"Cuisines\", axis=1)\n",
    "alldata = pd.concat((alldata, pd.DataFrame(cuisine_vals_list).fillna(0).astype(np.int8)), axis=1)\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding City as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City           Location\n",
      "--------------------------------------------------\n",
      "Pune           FTI College, Law College Road, Pune\n",
      "Bangalore      Sector 3, Marathalli\n",
      "Mumbai         Mumbai Central\n",
      "Noida          Sector 1, Noida\n",
      "Bangalore      Rmz Centennial, I Gate, Whitefield\n",
      "Delhi          Delhi University-GTB Nagar\n",
      "Pune           Yerawada, Pune, Maharashtra\n",
      "Delhi          Delhi Administration Flats, Timarpur\n",
      "Kolkata        Moulali, Kolkata\n",
      "Mumbai         Dockyard Road, Mumbai CST Area\n",
      "Pune           Pune University\n",
      "Kolkata        Gora Bazar, Rajbari, North Dumdum, Kolkata\n",
      "Noida          D-Block, Sector 63, Noida\n",
      "Noida          Sector 14, Noida\n",
      "Bangalore      Mico Layout, Stage 2, BTM Layout,Bangalore\n",
      "Gurgaon        Laxman Vihar Industrial Area, Sector 3A, Gurgoan\n",
      "Kolkata        Tiretti, Kolkata\n",
      "Mumbai         Sandhurst Road, Mumbai CST Area\n",
      "Pune           MG Road, Pune\n",
      "Hyderabad      Hyderabad Public School, Begumpet\n",
      "Bangalore      Majestic\n",
      "Kolkata        Chandni Chowk, Kolkata\n",
      "Delhi          Delhi High Court, India Gate\n",
      "Hyderabad      Chatta Bazaar, Malakpet, Hyderabad\n",
      "Gurgaon        Sector 63A,Gurgaon\n",
      "Delhi          Delhi Cantt.\n",
      "Mumbai         Tejas Nagar Colony, Wadala West, Mumbai\n",
      "Delhi          Babarpur, New Delhi, Delhi\n",
      "Pune           Nathan Road, Mangaldas Road, Pune\n",
      "Hyderabad      Panjetan Colony, Malakpet, Hyderabad\n",
      "Kolkata        Raja Bazar, Kolkata\n",
      "Hyderabad      Jaya Nagar, Saidabad, Hyderabad\n",
      "Hyderabad      Noorkhan Bazaar, Malakpet, Hyderabad\n",
      "Hyderabad      Musi Nagar, Malakpet, Hyderabad\n",
      "Bangalore      BTM Layout 1, Electronic City\n"
     ]
    }
   ],
   "source": [
    "city = ['Pune', 'Bangalore', 'Mumbai', 'Noida', 'Bangalore', 'Delhi', 'Pune', 'Delhi', 'Kolkata',\n",
    "        'Mumbai', 'Pune', 'Kolkata', 'Noida', 'Noida', 'Bangalore', 'Gurgaon', 'Kolkata',\n",
    "        'Mumbai', 'Pune', 'Hyderabad', 'Bangalore', 'Kolkata', 'Delhi', 'Hyderabad',\n",
    "        'Gurgaon', 'Delhi', 'Mumbai', 'Delhi', 'Pune', 'Hyderabad', 'Kolkata', 'Hyderabad', 'Hyderabad', 'Hyderabad', 'Bangalore']\n",
    "\n",
    "location = alldata['Location'].unique().tolist()\n",
    "\n",
    "city_mapping = dict(zip(location, city))\n",
    "print(\"{:<15}{}\".format('City', 'Location'))\n",
    "print(\"\".join(\"-\"*50))\n",
    "for key, val in city_mapping.items():\n",
    "    print(\"{:<15}{}\".format(val, key))\n",
    "\n",
    "alldata['City'] = alldata['Location'].map(city_mapping)\n",
    "alldata = alldata.drop(\"Location\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Feature Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Rating', 'Votes', 'Reviews']:\n",
    "    alldata[col] = pd.to_numeric(alldata[col], errors='coerce').fillna(-99)\n",
    "    \n",
    "alldata['Average_Cost'] = pd.to_numeric(alldata['Average_Cost'].str[1:].str.replace(',',''), errors='coerce')\n",
    "alldata['Average_Cost'] = alldata['Average_Cost'].fillna(-99).astype(int)\n",
    "\n",
    "alldata['Minimum_Order'] = alldata['Minimum_Order'].str[1:].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other useful Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restaurant',\n",
       " 'Average_Cost',\n",
       " 'Minimum_Order',\n",
       " 'Rating',\n",
       " 'Votes',\n",
       " 'Reviews',\n",
       " 'North Indian',\n",
       " 'French',\n",
       " 'Mithai',\n",
       " 'Konkan',\n",
       " 'Bohri',\n",
       " 'Cafe',\n",
       " 'Bakery',\n",
       " 'Turkish',\n",
       " 'North Eastern',\n",
       " 'Mishti',\n",
       " 'Bubble Tea',\n",
       " 'Hot dogs',\n",
       " 'Vietnamese',\n",
       " 'Pizza',\n",
       " 'Japanese',\n",
       " 'Odia',\n",
       " 'Mughlai',\n",
       " 'Tamil',\n",
       " 'Maharashtrian',\n",
       " 'Rolls',\n",
       " 'Momos',\n",
       " 'Bengali',\n",
       " 'Naga',\n",
       " 'Mangalorean',\n",
       " 'Indian',\n",
       " 'Thai',\n",
       " 'Mexican',\n",
       " 'Korean',\n",
       " 'Tibetan',\n",
       " 'Chettinad',\n",
       " 'Biryani',\n",
       " 'Parsi',\n",
       " 'Raw Meats',\n",
       " 'Street Food',\n",
       " 'Middle Eastern',\n",
       " 'Assamese',\n",
       " 'Burger',\n",
       " 'Rajasthani',\n",
       " 'Roast Chicken',\n",
       " 'Tex-Mex',\n",
       " 'South Indian',\n",
       " 'Bangladeshi',\n",
       " 'Ice Cream',\n",
       " 'Goan',\n",
       " 'Malaysian',\n",
       " 'Pok√©',\n",
       " 'Asian',\n",
       " 'Finger Food',\n",
       " 'Iranian',\n",
       " 'Cantonese',\n",
       " 'Coffee',\n",
       " 'South American',\n",
       " 'Seafood',\n",
       " 'Lucknowi',\n",
       " 'Charcoal Chicken',\n",
       " 'American',\n",
       " 'Bar Food',\n",
       " 'Paan',\n",
       " 'Malwani',\n",
       " 'Kebab',\n",
       " 'Lebanese',\n",
       " 'Belgian',\n",
       " 'Continental',\n",
       " 'Andhra',\n",
       " 'Frozen Yogurt',\n",
       " 'Wraps',\n",
       " 'Italian',\n",
       " 'Kashmiri',\n",
       " 'Bihari',\n",
       " 'African',\n",
       " 'Kerala',\n",
       " 'Sri Lankan',\n",
       " 'Greek',\n",
       " 'Chinese',\n",
       " 'Gujarati',\n",
       " 'Desserts',\n",
       " 'Awadhi',\n",
       " 'Juices',\n",
       " 'Indonesian',\n",
       " 'Healthy Food',\n",
       " 'Brazilian',\n",
       " 'European',\n",
       " 'Hyderabadi',\n",
       " 'Spanish',\n",
       " 'Portuguese',\n",
       " 'Afghan',\n",
       " 'BBQ',\n",
       " 'Arabian',\n",
       " 'Fast Food',\n",
       " 'Burmese',\n",
       " 'German',\n",
       " 'Steak',\n",
       " 'Sandwich',\n",
       " 'Modern Indian',\n",
       " 'Tea',\n",
       " 'Mediterranean',\n",
       " 'Beverages',\n",
       " 'Nepalese',\n",
       " 'Israeli',\n",
       " 'Sushi',\n",
       " 'Salad',\n",
       " 'City',\n",
       " 'Minimum_Order_Zero',\n",
       " 'Reviews_by_Votes',\n",
       " 'Minimum_Order_to_Cost',\n",
       " 'Location_num_Res',\n",
       " 'Restaurant_branch_count']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata['Minimum_Order_Zero'] = np.where(alldata['Minimum_Order'] == 0, 1, 0)\n",
    "\n",
    "alldata['Reviews_by_Votes'] = alldata['Reviews'] / alldata['Votes']\n",
    "alldata['Minimum_Order_to_Cost'] = alldata['Minimum_Order'] / alldata['Average_Cost']\n",
    "alldata[\"Location_num_Res\"] = alldata[\"City\"].map(alldata.groupby(\"City\").Restaurant.nunique())\n",
    "alldata[\"Restaurant_branch_count\"] = alldata[\"Restaurant\"].map(alldata[\"Restaurant\"].value_counts())\n",
    "\n",
    "alldata.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "num_cols = ['Votes', 'Reviews', 'Rating', 'Average_Cost', 'Minimum_Order', \n",
    "            'Restaurant_branch_count', 'Location_num_Res', 'Reviews_by_Votes', 'Minimum_Order_to_Cost']\n",
    "cat_cols = [col for col in alldata.columns if col not in num_cols]\n",
    "features = pd.get_dummies(alldata.drop(num_cols, axis=1), columns=cat_cols, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sparse.to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "num_features=scipy.sparse.coo_matrix(alldata[num_cols].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=scipy.sparse.hstack([features, num_features]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11094, 8882)\n",
      "(2774, 8882)\n"
     ]
    }
   ],
   "source": [
    "train_ohe = features[:train.shape[0], :]\n",
    "test_ohe = features[train.shape[0]:, :]\n",
    "\n",
    "print(train_ohe.shape)\n",
    "print(test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_ohe, train_target, test_size=0.20, random_state=314, stratify=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'objective': 'multiclass',\n",
       " 'metric': 'multi_logloss',\n",
       " 'verbose': 0,\n",
       " 'bagging_fraction': 0.8,\n",
       " 'bagging_freq': 1,\n",
       " 'num_class': 7,\n",
       " 'feature_fraction': 0.8,\n",
       " 'lambda_l1': 0.01,\n",
       " 'lambda_l2': 0.01,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_bin': 255,\n",
       " 'max_depth': -1,\n",
       " 'min_data_in_bin': 1,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'num_leaves': 31}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_fit_params={\"early_stopping_rounds\":50, \n",
    "            \"eval_metric\" : 'multi_logloss', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose':100\n",
    "           }\n",
    "\n",
    "lgb_params = {'boosting_type': 'gbdt',\n",
    " 'objective': 'multiclass',\n",
    " 'metric': 'multi_logloss',\n",
    " 'verbose': 0,\n",
    " 'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 1,\n",
    " 'num_class': 7,\n",
    " 'feature_fraction': 0.8,\n",
    " 'lambda_l1': 0.01,\n",
    " 'lambda_l2': 0.01,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_bin': 255,\n",
    " 'max_depth': -1,\n",
    " 'min_data_in_bin': 1,\n",
    " 'min_data_in_leaf': 1,\n",
    " 'num_leaves': 31}\n",
    "lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalid's multi_logloss: 0.582777\n",
      "[200]\tvalid's multi_logloss: 0.560735\n",
      "[300]\tvalid's multi_logloss: 0.555217\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid's multi_logloss: 0.554839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lgb = lgb.LGBMClassifier(n_estimators=10000, **lgb_params, random_state=123456789, n_jobs=-1)\n",
    "clf_lgb.fit(X_train, y_train, **lgb_fit_params)\n",
    "clf_lgb.best_iteration_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training on Complete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,\n",
       "               importance_type='split', lambda_l1=0.01, lambda_l2=0.01,\n",
       "               learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "               metric='multi_logloss', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_bin=1, min_data_in_leaf=1,\n",
       "               min_split_gain=0.0, n_estimators=363, n_jobs=-1, num_class=7,\n",
       "               num_leaves=31, objective='multiclass', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lgb_fulldata = lgb.LGBMClassifier(n_estimators=int(clf_lgb.best_iteration_*1.2), **lgb_params)\n",
    "clf_lgb_fulldata.fit(train_ohe, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 30s, sys: 768 ms, total: 16min 30s\n",
      "Wall time: 16min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=0.1, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf_fulldata=RandomForestClassifier(n_estimators=2000, max_features=0.1)\n",
    "clf_rf_fulldata.fit(train_ohe, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 12s, sys: 392 ms, total: 8min 13s\n",
      "Wall time: 8min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=0.1, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_rf2_fulldata=RandomForestClassifier(n_estimators=1000, max_features=0.1)\n",
    "clf_rf2_fulldata.fit(train_ohe, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling lightgbm and RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean((clf_lgb_fulldata.predict_proba(test_ohe), \n",
    "                       clf_rf_fulldata.predict_proba(test_ohe)), axis=0)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delivery_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Delivery_Time\n",
       "0    30 minutes\n",
       "1    30 minutes\n",
       "2    30 minutes\n",
       "3    30 minutes\n",
       "4    30 minutes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'submission_mean_ens_model17.xlsx'\n",
    "\n",
    "# Make submission\n",
    "submission = pd.DataFrame({target: pd.Series(predictions).map(class_map_rev).apply(lambda x: str(x)+\" minutes\")})\n",
    "submission.to_excel(filename, index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean\n",
    "predictions = hmean((np.clip(clf_lgb_fulldata.predict_proba(test_ohe), 0.001, 1),\n",
    "                     np.clip(clf_rf_fulldata.predict_proba(test_ohe), 0.001, 1)), axis=0)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delivery_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Delivery_Time\n",
       "0    30 minutes\n",
       "1    30 minutes\n",
       "2    30 minutes\n",
       "3    30 minutes\n",
       "4    30 minutes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'submission_hmean_ens_model17.xlsx'\n",
    "\n",
    "# Make submission\n",
    "submission2 = pd.DataFrame({target: pd.Series(predictions).map(class_map_rev).apply(lambda x: str(x)+\" minutes\")})\n",
    "submission2.to_excel(filename, index=False)\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean((clf_lgb_fulldata.predict_proba(test_ohe), \n",
    "                       clf_rf2_fulldata.predict_proba(test_ohe)), axis=0)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delivery_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Delivery_Time\n",
       "0    30 minutes\n",
       "1    30 minutes\n",
       "2    30 minutes\n",
       "3    30 minutes\n",
       "4    30 minutes"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'submission_mean2_ens_model17.xlsx'\n",
    "\n",
    "# Make submission\n",
    "submission3 = pd.DataFrame({target: pd.Series(predictions).map(class_map_rev).apply(lambda x: str(x)+\" minutes\")})\n",
    "submission3.to_excel(filename, index=False)\n",
    "submission3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer - Mode based Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pd.read_excel('submission_mean_ens_model17.xlsx', index_col=None)\n",
    "pred2 = pd.read_excel('submission_hmean_ens_model17.xlsx', index_col=None)\n",
    "pred3 = pd.read_excel('submission_mean2_ens_model17.xlsx', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (pd.concat((pred1['Delivery_Time'],\n",
    "                    pred2['Delivery_Time'],\n",
    "                    pred3['Delivery_Time']), axis=1)).mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delivery_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Delivery_Time\n",
       "0    30 minutes\n",
       "1    30 minutes\n",
       "2    30 minutes\n",
       "3    30 minutes\n",
       "4    30 minutes"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_final = pd.DataFrame({'Delivery_Time': predictions[0]})\n",
    "submission_final.to_excel(\"runs_3ensemble_v2.xlsx\", index=False)\n",
    "submission_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "527c4c1886404a0886c9aeca0e7cd180": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a390a6542d414a448316768f7e5b2691",
        "IPY_MODEL_83a842ad7d90455893db5025dbd3299f"
       ],
       "layout": "IPY_MODEL_ba4db8f8ed9e4c29a461f8fd61fa82bc"
      }
     },
     "83a842ad7d90455893db5025dbd3299f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a886f2331c5458ea1cd6998731d6556",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_e36959e5581646039d9a566b087b80eb",
       "value": "13868/|/| 13868/? [00:02&lt;00:00, 5334.04it/s]"
      }
     },
     "8a886f2331c5458ea1cd6998731d6556": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a390a6542d414a448316768f7e5b2691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b50b3cf5b6c6431e826912be7606e57e",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a69f720c913647d9b0b648f4be03e83d",
       "value": 1
      }
     },
     "a69f720c913647d9b0b648f4be03e83d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b50b3cf5b6c6431e826912be7606e57e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba4db8f8ed9e4c29a461f8fd61fa82bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e36959e5581646039d9a566b087b80eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
